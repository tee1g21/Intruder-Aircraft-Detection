{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Metric       Training     Validation\n",
      "                 Average Accuracy (0.684, 0.068) (0.603, 0.052)\n",
      "   Standard Deviation of Accuracy (0.226, 0.002) (0.154, 0.009)\n",
      "                    Best Accuracy (0.930, 0.026) (0.757, 0.037)\n",
      "                    Last Accuracy (0.920, 0.032) (0.726, 0.041)\n",
      "                      Overall AUC            NaN (0.533, 0.057)\n",
      "                 Maximum F1 Score            NaN (0.752, 0.038)\n",
      "                     Minimum Loss            NaN (0.803, 0.050)\n",
      "Difference in Average Loss Last N            NaN (0.764, 0.072)\n",
      "Standard Deviation of Loss Last N            NaN (0.152, 0.052)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_metric_tables(metric_tables):\n",
    "    def parse_tables_manual(metric_tables):\n",
    "        dataframes = []\n",
    "        for table in metric_tables:\n",
    "            lines = table.strip().split('\\n')\n",
    "            headers = lines[0].split(maxsplit=2)\n",
    "            data = []\n",
    "            for line in lines[1:]:\n",
    "                index_space = line.index(' ')\n",
    "                first_split = line[:index_space].strip()\n",
    "                remaining = line[index_space:].strip()\n",
    "                parts = remaining.rsplit(maxsplit=2)\n",
    "                if len(parts) == 3:\n",
    "                    data.append([parts[0], parts[1], parts[2]])\n",
    "                else:\n",
    "                    data.append([parts[0], np.nan, np.nan])\n",
    "            df = pd.DataFrame(data, columns=headers)\n",
    "            df[headers[1]] = pd.to_numeric(df[headers[1]], errors='coerce')\n",
    "            df[headers[2]] = pd.to_numeric(df[headers[2]], errors='coerce')\n",
    "            dataframes.append(df)\n",
    "        return dataframes\n",
    "\n",
    "    def calculate_statistics_ordered(dataframes):\n",
    "        metrics = dataframes[0]['Metric']\n",
    "        result_list = []\n",
    "        for metric in metrics:\n",
    "            metric_data = [df[df['Metric'] == metric] for df in dataframes]\n",
    "            metric_stats = {}\n",
    "            for col in ['Training', 'Validation']:\n",
    "                valid_data = pd.concat([md[col] for md in metric_data]).dropna()\n",
    "                if not valid_data.empty:\n",
    "                    mean_val = valid_data.mean()\n",
    "                    std_val = valid_data.std()\n",
    "                    metric_stats[col] = (mean_val, std_val)\n",
    "                else:\n",
    "                    metric_stats[col] = np.nan\n",
    "            result_list.append((metric, metric_stats))\n",
    "        return result_list\n",
    "\n",
    "    def format_output_ordered(statistics_ordered):\n",
    "        output_df = pd.DataFrame(columns=['Metric', 'Training', 'Validation'])\n",
    "        for metric, values in statistics_ordered:\n",
    "            row = {'Metric': metric}\n",
    "            for col in ['Training', 'Validation']:\n",
    "                if col in values and not pd.isna(values[col]):\n",
    "                    row[col] = f\"({values[col][0]:.3f}, {values[col][1]:.3f})\"\n",
    "                else:\n",
    "                    row[col] = np.nan\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        output_string = output_df.to_string(index=False)\n",
    "        return output_string\n",
    "\n",
    "    # Process the input tables\n",
    "    dataframes = parse_tables_manual(metric_tables)\n",
    "    statistics = calculate_statistics_ordered(dataframes)\n",
    "    output_table = format_output_ordered(statistics)\n",
    "    return output_table\n",
    "# Example usage\n",
    "metric_tables = [\n",
    "    \"\"\"                              Metric  Training  Validation\n",
    "0                   Average Accuracy     0.760       0.655\n",
    "1     Standard Deviation of Accuracy     0.223       0.146\n",
    "2                      Best Accuracy     0.959       0.773\n",
    "3                      Last Accuracy     0.956       0.773\n",
    "4                        Overall AUC       NaN       0.489\n",
    "5                   Maximum F1 Score       NaN       0.770\n",
    "6                       Minimum Loss       NaN       0.757\n",
    "7  Difference in Average Loss Last N       NaN       0.846\n",
    "8  Standard Deviation of Loss Last N       NaN       0.119\"\"\",\n",
    "\n",
    "\n",
    "\"\"\"                              Metric  Training  Validation\n",
    "0                   Average Accuracy     0.629       0.552\n",
    "1     Standard Deviation of Accuracy     0.227       0.154\n",
    "2                      Best Accuracy     0.907       0.714\n",
    "3                      Last Accuracy     0.906       0.709\n",
    "4                        Overall AUC       NaN       0.512\n",
    "5                   Maximum F1 Score       NaN       0.708\n",
    "6                       Minimum Loss       NaN       0.796\n",
    "7  Difference in Average Loss Last N       NaN       0.735\n",
    "8  Standard Deviation of Loss Last N       NaN       0.212\"\"\",\n",
    "\n",
    "\n",
    "\"\"\"                              Metric  Training  Validation\n",
    "0                   Average Accuracy     0.663       0.601\n",
    "1     Standard Deviation of Accuracy     0.227       0.163\n",
    "2                      Best Accuracy     0.925       0.783\n",
    "3                      Last Accuracy     0.897       0.697\n",
    "4                        Overall AUC       NaN       0.597\n",
    "5                   Maximum F1 Score       NaN       0.778\n",
    "6                       Minimum Loss       NaN       0.856\n",
    "7  Difference in Average Loss Last N       NaN       0.711\n",
    "8  Standard Deviation of Loss Last N       NaN       0.125\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # More tables would follow here\n",
    "]\n",
    "\n",
    "result = process_metric_tables(metric_tables)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
