{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from ultralytics import settings\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import yaml\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "max_workers=12\n",
    "\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings_version': '0.0.4', 'datasets_dir': 'D:\\\\Tom\\\\GitHub\\\\Third Year Project\\\\datasets', 'weights_dir': 'D:\\\\Tom\\\\GitHub\\\\Third Year Project\\\\Intruder-Aircraft-Detection\\\\weights', 'runs_dir': 'D:\\\\Tom\\\\GitHub\\\\Third Year Project\\\\Intruder-Aircraft-Detection\\\\runs', 'uuid': 'fdb5c10788ffaa41a9047dc764dd8a0a3287d6bec12c0c66234ac745c0366efa', 'sync': True, 'api_key': '', 'openai_api_key': '', 'clearml': True, 'comet': True, 'dvc': True, 'hub': True, 'mlflow': True, 'neptune': True, 'raytune': True, 'tensorboard': True, 'wandb': True}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Ultralytics settings\n",
    "print(settings) \n",
    "\n",
    "# GPU Utilisation\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "# Base paths for the images and labels\n",
    "train_images_path = 'datasets/AVOIDDS/images/train'\n",
    "train_labels_path = 'datasets/AVOIDDS/labels/train'\n",
    "val_images_path = 'datasets/AVOIDDS/images/valid'\n",
    "val_labels_path = 'datasets/AVOIDDS/labels/valid'\n",
    "\n",
    "# Load the metadata\n",
    "metadata_path = 'datasets/AVOIDDS/metadata.json'\n",
    "with open(metadata_path, 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "# Function to create a DataFrame from images and labels\n",
    "def create_dataframe(images_path, labels_path, metadata):\n",
    "\n",
    "    # List all files in the directories\n",
    "    image_files = [f for f in sorted(os.listdir(images_path)) if f.endswith('.jpg')]\n",
    "    label_files = [f for f in sorted(os.listdir(labels_path)) if f.endswith('.txt')]\n",
    "    \n",
    "    # Create tempory DataFrame so that final dataframe is in correct order\n",
    "    temp_df = pd.DataFrame({\n",
    "        'image_path': [str(images_path + '/' + file) for file in image_files],\n",
    "        'label_path': [str(labels_path + '/' + file) for file in label_files],\n",
    "    })\n",
    "\n",
    "    # Extract image indices to match with metadata\n",
    "    df = pd.DataFrame()\n",
    "    df['imageID'] = temp_df['image_path'].apply(lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "\n",
    "    # Add image and label paths to final dataframe\n",
    "    df['image_path'] = temp_df['image_path']\n",
    "    df['label_path'] = temp_df['label_path']\n",
    " \n",
    "    # Add metadata to each image entry\n",
    "    for key, value in metadata.items():\n",
    "        if '.' in key:  # Key represents a range\n",
    "            start, end = map(int, key.split('.'))\n",
    "            df.loc[df['imageID'].between(start, end), 'metadata'] = json.dumps(value)\n",
    "\n",
    "    # Convert the JSON strings in 'metadata' to dictionaries\n",
    "    df['metadata'] = df['metadata'].apply(json.loads)\n",
    "\n",
    "    # Expand the 'metadata' column into separate columns\n",
    "    metadata_df = pd.json_normalize(df['metadata'])\n",
    "    \n",
    "    # Concatenate the expanded metadata back to the original DataFrame\n",
    "    full_df = pd.concat([df.drop(['metadata'], axis=1), metadata_df], axis=1)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "# Create the DataFrames for the train and validation sets\n",
    "train_df = create_dataframe(train_images_path, train_labels_path, metadata)\n",
    "valid_df = create_dataframe(val_images_path, val_labels_path, metadata)\n",
    "\n",
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sub datasets\n",
    "\n",
    "# removes all files and folders from dataset directory\n",
    "def clear_directory(dir_path):    \n",
    "    for item in os.listdir(dir_path):\n",
    "        item_path = os.path.join(dir_path, item)\n",
    "        if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "            os.unlink(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "\n",
    "# remove directories if they exist\n",
    "def remove_if_exists(path, progress=None):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    elif os.path.isfile(path):\n",
    "        os.remove(path)    \n",
    "    if progress:\n",
    "        progress.update(1)\n",
    "\n",
    "## creates subsets of main dataset\n",
    "def create_dataset(dataset_name, filtered_train_df, filtered_valid_df, class_names=['aircraft'], dataset_dir=\"datasets/\"):\n",
    "    new_dataset_dir = Path(dataset_dir) / dataset_name\n",
    "    images_dir = Path(new_dataset_dir) / 'images'\n",
    "    labels_dir = Path(new_dataset_dir) / 'labels'\n",
    "\n",
    "    remove_if_exists(new_dataset_dir)\n",
    "\n",
    "    # Create directories\n",
    "    for subdir in ['train', 'valid']:\n",
    "        (images_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "        (labels_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def copy_file(src, dest):\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "    def copy_files_from_dataframe(df, img_dest_dir, label_dest_dir):\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Prepare futures for image and label copying\n",
    "            futures = [executor.submit(copy_file, row['image_path'], img_dest_dir / f\"{Path(row['image_path']).name}\") for _, row in df.iterrows()]\n",
    "            futures += [executor.submit(copy_file, row['label_path'], label_dest_dir / f\"{Path(row['label_path']).name}\") for _, row in df.iterrows()]\n",
    "            \n",
    "            # Initialize progress bar\n",
    "            pbar = tqdm(total=len(futures), desc='Copying files')\n",
    "            for future in as_completed(futures):\n",
    "                # Update progress bar upon task completion\n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "\n",
    "    print(\"Copying training files:\")\n",
    "    copy_files_from_dataframe(filtered_train_df, images_dir / 'train', labels_dir / 'train')\n",
    "    print(\"Copying validation files:\")\n",
    "    copy_files_from_dataframe(filtered_valid_df, images_dir / 'valid', labels_dir / 'valid')\n",
    "\n",
    "    # Construct the YAML content with the desired structure\n",
    "    yaml_content = {\n",
    "        'path': str(f'../{new_dataset_dir}').replace('\\\\', '/'),  # Ensuring forward slashes\n",
    "        'train': str('images/train'),\n",
    "        'val': str('images/valid'),\n",
    "        'names': {index: name for index, name in enumerate(class_names)}\n",
    "    }  \n",
    "\n",
    "    yaml_path = new_dataset_dir / f\"{dataset_name}.yaml\"\n",
    "    with open(yaml_path, 'w') as file:\n",
    "        yaml.dump(yaml_content, file, sort_keys=False)\n",
    "\n",
    "    print(f\"Dataset '{dataset_name}' created at {dataset_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying training files:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef7b960b91d474aa214d9e15fd3613b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Copying files:   0%|          | 0/43200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation files:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0887b7de23a64b2db1b97624114d5014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Copying files:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'cessna_only' created at datasets/\n"
     ]
    }
   ],
   "source": [
    "# TEST - cessna only dataset test\n",
    "\n",
    "test_train_df = train_df[train_df['ac'] == 'Cessna Skyhawk']\n",
    "test_valid_df = valid_df[valid_df['ac'] == 'Cessna Skyhawk']\n",
    "\n",
    "dataset_name = 'cessna_only'\n",
    "\n",
    "create_dataset(dataset_name, test_train_df, test_valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and format labels\n",
    "\n",
    "# extracts class names and bboxes from all objects in label\n",
    "def load_yolo_labels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = [line.strip().split() for line in file.readlines()]\n",
    "        bboxes = [list(map(float, label[1:])) for label in labels]\n",
    "        class_labels = [int(label[0]) for label in labels]\n",
    "    return bboxes, class_labels\n",
    "\n",
    "# takes class names and augmented bbox and converts into yolo label format\n",
    "def format_yolo_label(class_labels, augmented_bboxes):\n",
    "    label_str = \"\"\n",
    "    for class_label, bbox in zip(class_labels, augmented_bboxes):\n",
    "        label_str += f\"{class_label} \" + \" \".join(f\"{x:.6f}\" for x in bbox) + \"\\n\"\n",
    "    return label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## horizontal/vertical flip\n",
    "\n",
    "def augment_flip(image_path, label_path, orientation, p=1.0):\n",
    "    # Load image - openCV\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load labels\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    # Define the augmentation based on the orientation parameter\n",
    "    if orientation == 'h':\n",
    "        flip = A.HorizontalFlip(p=p)\n",
    "    elif orientation == 'v':\n",
    "        flip = A.VerticalFlip(p=p)\n",
    "    else:\n",
    "        raise ValueError(\"Orientation must be 'h' or 'v'\")\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        flip,\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    augmented_image = transformed['image']\n",
    "    augmented_bboxes = transformed['bboxes']\n",
    "\n",
    "    \n",
    "    # YOLO formatted label: [class_id, x_center, y_center, width, height]\n",
    "    augmented_label = format_yolo_label(class_labels, augmented_bboxes)\n",
    "    \n",
    "    return augmented_image, augmented_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rotation\n",
    "\n",
    "def augment_rotation(image_path, label_path, angle, p=1.0):\n",
    "   \n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load labels\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    # Define the augmentation with rotation\n",
    "    transform = A.Compose([\n",
    "        A.Rotate(limit=(angle, angle), p=p, border_mode=cv2.BORDER_CONSTANT),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    augmented_image = transformed['image']\n",
    "    augmented_bboxes = transformed['bboxes']\n",
    "    \n",
    "\n",
    "    # Convert augmented bboxes and class labels back to YOLO format\n",
    "    augmented_label = format_yolo_label(class_labels, augmented_bboxes)\n",
    "    \n",
    "    return augmented_image, augmented_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast and brightness\n",
    "\n",
    "# Alpha - contrast control (1.0-3.0)\n",
    "# Beta - brightness control (-100 to 100)\n",
    "def augment_brightness_contrast(image_path, alpha=1.0, beta=0):\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Apply brightness and contrast adjustment\n",
    "    augmented_image = np.clip(alpha * image.astype(np.float32) + beta, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram equalisation with CLAHE\n",
    "\n",
    "def augment_histogram_equalization(image_path, p=1.0):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Define the augmentation\n",
    "    transform = A.Compose([\n",
    "        A.CLAHE(p),\n",
    "    ])\n",
    "    \n",
    "    # Apply the augmentation\n",
    "    transformed = transform(image=image)\n",
    "    augmented_image = transformed['image']\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white balancing - gray word algorithm\n",
    "\n",
    "def augment_white_balance(image_path):\n",
    "  \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Calculate the mean of each channel\n",
    "    mr = np.mean(image[:, :, 0])\n",
    "    mg = np.mean(image[:, :, 1])\n",
    "    mb = np.mean(image[:, :, 2])\n",
    "    \n",
    "    # Calculate the overall mean\n",
    "    mgray = (mr + mg + mb) / 3\n",
    "    \n",
    "    # Scale the channels based on the Gray World assumption\n",
    "    image[:, :, 0] = np.clip(image[:, :, 0] * (mgray / mr), 0, 255)\n",
    "    image[:, :, 1] = np.clip(image[:, :, 1] * (mgray / mg), 0, 255)\n",
    "    image[:, :, 2] = np.clip(image[:, :, 2] * (mgray / mb), 0, 255)\n",
    "    \n",
    "    augmented_image = image.astype(np.uint8)\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharpening \n",
    "\n",
    "def augment_sharpen(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Kernels from literature research\n",
    "    kernel_1 = np.array([[0, -1, 0],\n",
    "                         [-1, 5, -1],\n",
    "                         [0, -1, 0]], dtype=np.float32)\n",
    "    \n",
    "    kernel_2 = np.array([[-1, -2, -1],\n",
    "                         [-2, 13, -2],\n",
    "                         [-1, -2, -1]], dtype=np.float32)\n",
    "\n",
    "    kernel_2 = np.array([[-1, -2, -1],\n",
    "                         [-2, 16, -2],\n",
    "                         [-1, -2, -1]], dtype=np.float32)\n",
    "    \n",
    "    # Apply the sharpening kernel to the image\n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel_1)\n",
    "    \n",
    "    return sharpened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guassian noise\n",
    "\n",
    "def augment_gaussian_noise(image_path, var_limit=(10.0, 50.0)):\n",
    "   \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Define the augmentation\n",
    "    transform = A.Compose([\n",
    "        A.GaussNoise(var_limit=var_limit, mean=0, p=1.0),\n",
    "    ])\n",
    "    \n",
    "    # Apply the augmentation\n",
    "    transformed = transform(image=image)\n",
    "    augmented_image = transformed['image']\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom \n",
    "\n",
    "# zoom factor: No zoom = 1, Full zoom (bounding box takes up entire picture) = 10\n",
    "def augment_zoom(image_path, label_path, zoom_factor=1.5):\n",
    "\n",
    "    # adjust zoom factor so that 1 = no zoom\n",
    "    zoom_factor = zoom_factor / 10\n",
    "\n",
    "    # Load image and labels\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "\n",
    "    # Calculate the crop dimensions based on the bounding box and zoom factor\n",
    "    x_center, y_center, bbox_width, bbox_height = bboxes[0]  # Assuming one object\n",
    "    x_center *= image.shape[1]  # Convert from relative to absolute coordinates\n",
    "    y_center *= image.shape[0]\n",
    "    bbox_width *= image.shape[1]\n",
    "    bbox_height *= image.shape[0]\n",
    "\n",
    "    # Define the crop dimensions\n",
    "    crop_width = int(bbox_width / zoom_factor)\n",
    "    crop_height = int(bbox_height / zoom_factor)\n",
    "    \n",
    "    # Calculate the crop coordinates\n",
    "    x_min = max(0, int(x_center - crop_width / 2))\n",
    "    y_min = max(0, int(y_center - crop_height / 2))\n",
    "    x_max = min(image.shape[1], int(x_center + crop_width / 2))\n",
    "    y_max = min(image.shape[0], int(y_center + crop_height / 2))\n",
    "\n",
    "    # Define Albumentations transform for cropping and resizing\n",
    "    transform = A.Compose([\n",
    "        A.Crop(x_min=x_min, y_min=y_min, x_max=x_max, y_max=y_max, p=1.0),\n",
    "        A.Resize(height=image.shape[0], width=image.shape[1], p=1.0)\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    augmented_image = transformed['image']\n",
    "    augmented_bboxes = transformed['bboxes']\n",
    "    \n",
    "    # ensure bboxes do not exceed image\n",
    "    clamped_bboxes = [clamp_bbox_values(bbox) for bbox in augmented_bboxes]\n",
    "\n",
    "\n",
    "    # The transformed bboxes are already in YOLO format\n",
    "    augmented_label = format_yolo_label(class_labels, clamped_bboxes)\n",
    "\n",
    "    return augmented_image, augmented_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - overlay bboxes on images\n",
    "\n",
    "def overlay_bbox(image_path, label_path):\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Load labels\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    for bbox, class_label in zip(bboxes, class_labels):\n",
    "        x_center, y_center, bbox_width, bbox_height = bbox\n",
    "        x_min = (x_center - bbox_width / 2) * width\n",
    "        y_min = (y_center - bbox_height / 2) * height\n",
    "        \n",
    "        rect = patches.Rectangle((x_min, y_min), bbox_width * width, bbox_height * height,\n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(x_min, y_min - 2, str(class_label), color='red', fontsize=10, \n",
    "                 bbox=dict(facecolor='white', alpha=0.5, edgecolor='red', boxstyle='round'))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - block to test aug methods\n",
    "\n",
    "image = '5'\n",
    "dataset = 'train-aug'\n",
    "aug_type = 'rotation'\n",
    "\n",
    "test_image_path = f'datasets/cessna_only/images/{dataset}/{image}.jpg'\n",
    "test_label_path = f'datasets/cessna_only/labels/{dataset}/{image}.txt'\n",
    "\n",
    "aug_image_path = f'datasets/cessna_only/images/{dataset}/{image}-{aug_type}.jpg'\n",
    "aug_label_path = f'datasets/cessna_only/labels/{dataset}/{image}-{aug_type}.txt'\n",
    "\n",
    "overlay_bbox(aug_image_path, aug_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Augmented Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image and label\n",
    "def save_image(path, image):\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    \n",
    "    # Convert from RGB to BGR\n",
    "    image_to_save = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(path, image_to_save)\n",
    "\n",
    "# save label\n",
    "def save_label(path, contents):\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    \n",
    "    # Now, save the file\n",
    "    with open(path, 'w') as label_file:\n",
    "        label_file.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create augmented dataset structure\n",
    "        \n",
    "## augmented dataset structure\n",
    "def create_augmented_dataset_structure(original_dataset_path):\n",
    "  \n",
    "    # Create train-aug paths\n",
    "    images_train_aug_path = original_dataset_path + '/images/train-aug'\n",
    "    labels_train_aug_path = original_dataset_path + '/labels/train-aug'\n",
    "\n",
    "    dataset_name, _ = os.path.splitext(os.path.basename(original_dataset_path))\n",
    "\n",
    "\n",
    "    # Path for original and new yaml\n",
    "    original_yaml_path = original_dataset_path + f'/{dataset_name}.yaml'\n",
    "    augmented_yaml_path = original_dataset_path + f'/{dataset_name}-aug.yaml'\n",
    "\n",
    "    paths_to_remove = [\n",
    "        images_train_aug_path,\n",
    "        labels_train_aug_path,\n",
    "        augmented_yaml_path\n",
    "    ]   \n",
    "\n",
    "    # Replace existing directories\n",
    "    with tqdm(total=len(paths_to_remove), desc=\"Removing existing directories/files\") as progress:\n",
    "        # Check and remove each path, updating progress\n",
    "        for path in paths_to_remove:\n",
    "            remove_if_exists(path, progress)\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(images_train_aug_path, exist_ok=True)\n",
    "    os.makedirs(labels_train_aug_path, exist_ok=True)\n",
    "    \n",
    "    # create new yaml with aug appended to train  \n",
    "    with open(original_yaml_path, 'r') as file:\n",
    "        dataset_config = yaml.safe_load(file) \n",
    "\n",
    "    dataset_config['train'] += \"-aug\"\n",
    "\n",
    "    with open(augmented_yaml_path, 'w') as file:\n",
    "        yaml.safe_dump(dataset_config, file, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment datastets\n",
    "\n",
    "# copies all files to another directory \n",
    "def copy_directory_contents_concurrently(src_dir, dst_dir):\n",
    "     \n",
    "    # Retrieve a list of source file paths\n",
    "    src_files = [os.path.join(src_dir, file_name) for file_name in os.listdir(src_dir)]\n",
    "    dst_files = [os.path.join(dst_dir, os.path.basename(file_path)) for file_path in src_files]\n",
    "    \n",
    "    # Copy files concurrently\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        list(tqdm(executor.map(shutil.copy2, src_files, dst_files), total=len(src_files), desc=\"Copying files\"))\n",
    "\n",
    "# augments and saves individual image and label\n",
    "def augment_image(image_path, images_aug_dir, label_path, labels_aug_dir, method_name, method_info):\n",
    "    \n",
    "    # raw name of image and label without file extension\n",
    "    image_name, _ = os.path.splitext(os.path.basename(image_path))\n",
    "    label_name, _ = os.path.splitext(os.path.basename(label_path))\n",
    "\n",
    "    # throw error if image does not match label\n",
    "    if image_name != label_name:\n",
    "        raise ValueError(f\"ERROR: Filename mismatch: {image_name} and {label_name} do not match.\")\n",
    "\n",
    "    # create filenames for augmented images\n",
    "    aug_image_filename = f\"{image_name}-{method_name}.jpg\"\n",
    "    aug_label_filename = f\"{label_name}-{method_name}.txt\"\n",
    "    \n",
    "    # Determine which augmentation function to call based on the method name\n",
    "    if method_name == 'flip':\n",
    "        augmented_image, augmented_label = augment_flip(image_path, label_path, **method_info['parameters'])\n",
    "    elif method_name == 'rotation':\n",
    "        augmented_image, augmented_label = augment_rotation(image_path, label_path, **method_info['parameters'])\n",
    "    elif method_name == 'brightness_contrast':\n",
    "        augmented_image = augment_brightness_contrast(image_path, **method_info['parameters'])\n",
    "        augmented_label = open(label_path).read()  # No change to label for this augmentation\n",
    "    elif method_name == 'gaussian_noise':\n",
    "        augmented_image = augment_gaussian_noise(image_path, **method_info['parameters'])\n",
    "        augmented_label = open(label_path).read()  # No change to label for this augmentation\n",
    "    elif method_name == 'histogram_equalization':\n",
    "        augmented_image = augment_histogram_equalization(image_path, **method_info['parameters'])\n",
    "        augmented_label = open(label_path).read()  # No change to label for this augmentation\n",
    "    elif method_name == 'white_balance':\n",
    "        augmented_image = augment_white_balance(image_path)\n",
    "        augmented_label = open(label_path).read()  # No change to label for this augmentation\n",
    "    elif method_name == 'sharpen':\n",
    "        augmented_image = augment_sharpen(image_path)\n",
    "        augmented_label = open(label_path).read()  # No change to label for this augmentation\n",
    "    elif method_name == 'zoom':\n",
    "        augmented_image, augmented_label = augment_zoom(image_path, label_path, **method_info['parameters'])\n",
    "    \n",
    "    # Save the augmented image and label\n",
    "    save_image(images_aug_dir + aug_image_filename, augmented_image)\n",
    "    save_label(labels_aug_dir + aug_label_filename, augmented_label)\n",
    "\n",
    "\n",
    "\n",
    "def augment_dataset(original_dataset_path, augmentation_metadata):\n",
    "    \n",
    "    # reconstruct dataset with augmentation directories and yaml\n",
    "    create_augmented_dataset_structure(original_dataset_path)\n",
    "\n",
    "    # new train directories\n",
    "    images_dir = original_dataset_path + '/images/train/'\n",
    "    images_aug_dir = original_dataset_path + '/images/train-aug/'\n",
    "    labels_dir = original_dataset_path + '/labels/train/'\n",
    "    labels_aug_dir = original_dataset_path + '/labels/train-aug/'\n",
    "\n",
    "    # copy train and image labels to train-aug\n",
    "    copy_directory_contents_concurrently(images_dir, images_aug_dir)\n",
    "    copy_directory_contents_concurrently(labels_dir, labels_aug_dir)\n",
    "\n",
    "    # training images \n",
    "    image_paths = [os.path.join(images_aug_dir, img_name) for img_name in os.listdir(images_aug_dir)]\n",
    "\n",
    "    # Apply augmentations based on metadata\n",
    "    total_augmentations = sum(int(len(image_paths) * info['apply_to_percentage']) for info in augmentation_metadata['methods'].values())\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for method_name, method_info in augmentation_metadata['methods'].items():\n",
    "            selected_images = random.sample(image_paths, int(len(image_paths) * method_info['apply_to_percentage']))\n",
    "            selected_labels = [path.replace(images_aug_dir, labels_aug_dir).replace('.jpg', '.txt') for path in selected_images]\n",
    "            \n",
    "            for image_path, label_path in zip(selected_images, selected_labels):\n",
    "                # Schedule the augmentation to be applied concurrently\n",
    "                futures.append(executor.submit(augment_image, image_path, images_aug_dir, label_path, labels_aug_dir, method_name, method_info))\n",
    "\n",
    "        # Progress bar for the augmentation tasks\n",
    "        for _ in tqdm(as_completed(futures), total=total_augmentations, desc=\"Applying augmentations\"):\n",
    "            pass\n",
    "    \n",
    "    # tries and returns error for every image that failed to be augmented - most likely bounding box boundary error\n",
    "    for future in futures:\n",
    "        if not future.done():\n",
    "            print(\"A future did not complete.\")  \n",
    "        try:\n",
    "            future.result()  # re-raise exception that occurred\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dir = \"datasets/cessna_only\"\n",
    "\n",
    "augmentation_metadata = {\n",
    "    'methods': {\n",
    "        'flip': {\n",
    "            'parameters': {\n",
    "                'orientation': 'h',  # Could be 'h' for horizontal or 'v' for vertical\n",
    "                'p': 1.0  # Probability of applying the augmentation\n",
    "            },\n",
    "            'apply_to_percentage': 0.1  # 50% of the training images\n",
    "        },\n",
    "        'rotation': {\n",
    "            'parameters': {\n",
    "                'angle': 90,  # Rotation angle\n",
    "                'p': 1.0  # Probability of applying the augmentation\n",
    "            },\n",
    "            'apply_to_percentage': 0.1  # 30% of the training images\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "augment_dataset(test_dataset_dir, augmentation_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for each specfic test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
