{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import yaml\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "import torch\n",
    "from ultralytics import settings\n",
    "from ultralytics import YOLO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'settings_version': '0.0.4', 'datasets_dir': 'D:\\\\Tom\\\\GitHub\\\\Third Year Project\\\\datasets', 'weights_dir': 'D:\\\\Tom\\\\GitHub\\\\Third Year Project\\\\Intruder-Aircraft-Detection\\\\weights', 'runs_dir': 'D:\\\\Tom\\\\GitHub\\\\Third Year Project\\\\Intruder-Aircraft-Detection\\\\runs', 'uuid': 'fdb5c10788ffaa41a9047dc764dd8a0a3287d6bec12c0c66234ac745c0366efa', 'sync': True, 'api_key': '', 'openai_api_key': '', 'clearml': True, 'comet': True, 'dvc': True, 'hub': True, 'mlflow': True, 'neptune': True, 'raytune': True, 'tensorboard': True, 'wandb': True}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Ultralytics settings\n",
    "print(settings) \n",
    "\n",
    "# GPU Utilisation\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64800 entries, 0 to 64799\n",
      "Data columns (total 23 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   imageID      64800 non-null  int64  \n",
      " 1   image_path   64800 non-null  object \n",
      " 2   label_path   64800 non-null  object \n",
      " 3   location     64800 non-null  object \n",
      " 4   enrange      64800 non-null  float64\n",
      " 5   urange       64800 non-null  float64\n",
      " 6   weather      64800 non-null  int64  \n",
      " 7   daystart     64800 non-null  float64\n",
      " 8   dayend       64800 non-null  float64\n",
      " 9   num_train    64800 non-null  int64  \n",
      " 10  num_valid    64800 non-null  int64  \n",
      " 11  append       64800 non-null  bool   \n",
      " 12  datasetname  64800 non-null  object \n",
      " 13  ac           64800 non-null  object \n",
      " 14  allweather   64800 non-null  bool   \n",
      " 15  newac        64800 non-null  bool   \n",
      " 16  own_h        64800 non-null  object \n",
      " 17  own_p_max    64800 non-null  float64\n",
      " 18  own_r_max    64800 non-null  float64\n",
      " 19  intr_h       64800 non-null  object \n",
      " 20  vfov         64800 non-null  float64\n",
      " 21  hfov         64800 non-null  float64\n",
      " 22  outdir       64800 non-null  object \n",
      "dtypes: bool(3), float64(8), int64(4), object(8)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Base paths for the images and labels\n",
    "train_images_path = 'datasets/AVOIDDS/images/train'\n",
    "train_labels_path = 'datasets/AVOIDDS/labels/train'\n",
    "val_images_path = 'datasets/AVOIDDS/images/valid'\n",
    "val_labels_path = 'datasets/AVOIDDS/labels/valid'\n",
    "\n",
    "# Load the metadata\n",
    "metadata_path = 'datasets/AVOIDDS/metadata.json'\n",
    "with open(metadata_path, 'r') as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "# Function to create a DataFrame from images and labels\n",
    "def create_dataframe(images_path, labels_path, metadata):\n",
    "\n",
    "    # List all files in the directories\n",
    "    image_files = [f for f in sorted(os.listdir(images_path)) if f.endswith('.jpg')]\n",
    "    label_files = [f for f in sorted(os.listdir(labels_path)) if f.endswith('.txt')]\n",
    "    \n",
    "    # Create tempory DataFrame so that final dataframe is in correct order\n",
    "    temp_df = pd.DataFrame({\n",
    "        'image_path': [str(images_path + '/' + file) for file in image_files],\n",
    "        'label_path': [str(labels_path + '/' + file) for file in label_files],\n",
    "    })\n",
    "\n",
    "    # Extract image indices to match with metadata\n",
    "    df = pd.DataFrame()\n",
    "    df['imageID'] = temp_df['image_path'].apply(lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "\n",
    "    # Add image and label paths to final dataframe\n",
    "    df['image_path'] = temp_df['image_path']\n",
    "    df['label_path'] = temp_df['label_path']\n",
    " \n",
    "    # Add metadata to each image entry\n",
    "    for key, value in metadata.items():\n",
    "        if '.' in key:  # Key represents a range\n",
    "            start, end = map(int, key.split('.'))\n",
    "            df.loc[df['imageID'].between(start, end), 'metadata'] = json.dumps(value)\n",
    "\n",
    "    # Convert the JSON strings in 'metadata' to dictionaries\n",
    "    df['metadata'] = df['metadata'].apply(json.loads)\n",
    "\n",
    "    # Expand the 'metadata' column into separate columns\n",
    "    metadata_df = pd.json_normalize(df['metadata'])\n",
    "    \n",
    "    # Concatenate the expanded metadata back to the original DataFrame\n",
    "    full_df = pd.concat([df.drop(['metadata'], axis=1), metadata_df], axis=1)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "# Create the DataFrames for the train and validation sets\n",
    "train_df = create_dataframe(train_images_path, train_labels_path, metadata)\n",
    "valid_df = create_dataframe(val_images_path, val_labels_path, metadata)\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_name, filtered_train_df, filtered_valid_df, class_names=['aircraft'], dataset_dir=\"datasets/\"):\n",
    "    dataset_dir = Path(dataset_dir) / dataset_name\n",
    "    images_dir = dataset_dir / 'images'\n",
    "    labels_dir = dataset_dir / 'labels'\n",
    "\n",
    "    # Create directories\n",
    "    for subdir in ['train', 'valid']:\n",
    "        (images_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "        (labels_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def copy_file(src, dest):\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "    def copy_files_concurrently(df, img_dest_dir, label_dest_dir):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            # Prepare futures for image and label copying\n",
    "            futures = [executor.submit(copy_file, row['image_path'], img_dest_dir / f\"{Path(row['image_path']).name}\") for _, row in df.iterrows()]\n",
    "            futures += [executor.submit(copy_file, row['label_path'], label_dest_dir / f\"{Path(row['label_path']).name}\") for _, row in df.iterrows()]\n",
    "            \n",
    "            # Initialize progress bar\n",
    "            pbar = tqdm(total=len(futures), desc='Copying files')\n",
    "            for future in as_completed(futures):\n",
    "                # Update progress bar upon task completion\n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "\n",
    "    print(\"Copying training files:\")\n",
    "    copy_files_concurrently(filtered_train_df, images_dir / 'train', labels_dir / 'train')\n",
    "    print(\"Copying validation files:\")\n",
    "    copy_files_concurrently(filtered_valid_df, images_dir / 'valid', labels_dir / 'valid')\n",
    "\n",
    "    # Construct the YAML content with the desired structure\n",
    "    yaml_content = {\n",
    "        'path': str(f'../{dataset_dir}').replace('\\\\', '/'),  # Ensuring forward slashes\n",
    "        'train': str('images/train').replace('\\\\', '/'),\n",
    "        'val': str('images/valid').replace('\\\\', '/'),\n",
    "        'names': {index: name for index, name in enumerate(class_names)}\n",
    "    }  \n",
    "\n",
    "    yaml_path = dataset_dir / f\"{dataset_name}.yaml\"\n",
    "    with open(yaml_path, 'w') as file:\n",
    "        yaml.dump(yaml_content, file, sort_keys=False)\n",
    "\n",
    "    print(f\"Dataset '{dataset_name}' created at {dataset_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying training files:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ddade4d6d146408316c10ca1e35c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Copying files:   0%|          | 0/21600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation files:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea6eca857a94a64bcfd3674fec23cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Copying files:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'weather2' created at datasets\\weather2\n"
     ]
    }
   ],
   "source": [
    "cessna_train_df = train_df[train_df['weather'] == 1]\n",
    "cessna_valid_df = valid_df[valid_df['weather'] == 1]\n",
    "\n",
    "dataset_name = 'weather2'\n",
    "\n",
    "create_dataset(dataset_name, cessna_train_df, cessna_valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts class names and bboxes from all objects in label\n",
    "def load_yolo_labels(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        labels = [line.strip().split() for line in file.readlines()]\n",
    "        bboxes = [list(map(float, label[1:])) for label in labels]\n",
    "        class_labels = [int(label[0]) for label in labels]\n",
    "    return bboxes, class_labels\n",
    "\n",
    "# takes class names and augmented bbox and converts into yolo label format\n",
    "def format_yolo_label(class_labels, augmented_bboxes):\n",
    "    label_str = \"\"\n",
    "    for class_label, bbox in zip(class_labels, augmented_bboxes):\n",
    "        label_str += f\"{class_label} \" + \" \".join(f\"{x:.6f}\" for x in bbox) + \"\\n\"\n",
    "    return label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## horizontal/vertical flip\n",
    "\n",
    "def augment_flip(image_path, label_path, orientation, p=1.0):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load labels\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    # Define the augmentation based on the orientation parameter\n",
    "    if orientation == 'h':\n",
    "        flip = A.HorizontalFlip(p=p)\n",
    "    elif orientation == 'v':\n",
    "        flip = A.VerticalFlip(p=p)\n",
    "    else:\n",
    "        raise ValueError(\"Orientation must be 'h' or 'v'\")\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        flip,\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    augmented_image = transformed['image']\n",
    "    augmented_bboxes = transformed['bboxes']\n",
    "    \n",
    "    # YOLO formatted label: [class_id, x_center, y_center, width, height]\n",
    "    augmented_label = format_yolo_label(class_labels, augmented_bboxes)\n",
    "    \n",
    "    return augmented_image, augmented_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rotation\n",
    "\n",
    "def augment_rotation(image_path, label_path, angle, p=1.0):\n",
    "   \n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load labels\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    # Define the augmentation with rotation\n",
    "    transform = A.Compose([\n",
    "        A.Rotate(limit=(angle, angle), p=p, border_mode=cv2.BORDER_CONSTANT, fit_output=True),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "    augmented_image = transformed['image']\n",
    "    augmented_bboxes = transformed['bboxes']\n",
    "    \n",
    "    # Convert augmented bboxes and class labels back to YOLO format\n",
    "    augmented_label = format_yolo_label(class_labels, augmented_bboxes)\n",
    "    \n",
    "    return augmented_image, augmented_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contrast and brightness\n",
    "\n",
    "# Alpha - contrast control (1.0-3.0)\n",
    "# Beta - brightness control (-100 to 100)\n",
    "def augment_brightness_contrast(image_path, alpha=1.0, beta=0):\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Apply brightness and contrast adjustment\n",
    "    augmented_image = np.clip(alpha * image.astype(np.float32) + beta, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tester method to overlay bboxes on images\n",
    "\n",
    "def overlay_bbox(image_path, label_path):\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Load labels\n",
    "    bboxes, class_labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    for bbox, class_label in zip(bboxes, class_labels):\n",
    "        x_center, y_center, bbox_width, bbox_height = bbox\n",
    "        x_min = (x_center - bbox_width / 2) * width\n",
    "        y_min = (y_center - bbox_height / 2) * height\n",
    "        \n",
    "        rect = patches.Rectangle((x_min, y_min), bbox_width * width, bbox_height * height,\n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(x_min, y_min - 2, str(class_label), color='red', fontsize=10, \n",
    "                 bbox=dict(facecolor='white', alpha=0.5, edgecolor='red', boxstyle='round'))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_label(label_path):\n",
    "#\n",
    "#    # Placeholder for reading the label file in YOLO format\n",
    "#    pass\n",
    "#\n",
    "#def write_label(label_path, bboxes, image_shape):\n",
    "#    \n",
    "#    # Placeholder for writing the label file in YOLO format\n",
    "#    pass\n",
    "#\n",
    "#def augment_image(image_path, label_path, augmentation):\n",
    "#    image = cv2.imread(image_path)\n",
    "#    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#    bboxes = read_label(label_path)\n",
    "#\n",
    "#    # Note that bboxes should be normalized (i.e., in the range [0, 1])\n",
    "#    transformed = augmentation(image=image, bboxes=bboxes)\n",
    "#    transformed_image = transformed['image']\n",
    "#    transformed_bboxes = transformed['bboxes']\n",
    "#\n",
    "#    # Denormalize bboxes here if your write_label function expects that\n",
    "#    write_label(label_path, transformed_bboxes, transformed_image.shape)\n",
    "#\n",
    "#    cv2.imwrite(image_path, cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR))\n",
    "#\n",
    "## Zoom in/out\n",
    "#def zoom(image_path, label_path, min_zoom=0.8, max_zoom=1.2):\n",
    "#    augmentation = A.Compose([\n",
    "#        A.RandomScale(scale_limit=(min_zoom - 1, max_zoom - 1), p=1.0)\n",
    "#    ], bbox_params=A.BboxParams(format='yolo', label_fields=[]))\n",
    "#    \n",
    "#    augment_image(image_path, label_path, augmentation)\n",
    "#\n",
    "#\n",
    "\n",
    "## Contrast and Brightness\n",
    "#def adjust_contrast_brightness(image_path, label_path, brightness_limit=0.2, contrast_limit=0.2):\n",
    "#    augmentation = A.Compose([\n",
    "#        A.RandomBrightnessContrast(brightness_limit=brightness_limit, contrast_limit=contrast_limit, p=1.0)\n",
    "#    ])\n",
    "#    \n",
    "#    augment_image(image_path, label_path, augmentation)\n",
    "#\n",
    "## Histogram Equalization\n",
    "#def histogram_equalization(image_path, label_path):\n",
    "#    augmentation = A.Compose([\n",
    "#        A.HistogramMatching(p=1.0)\n",
    "#    ])\n",
    "#    \n",
    "#    augment_image(image_path, label_path, augmentation)\n",
    "#\n",
    "## White Balance (using FancyPCA for color augmentation which can simulate white balance shifts)\n",
    "#def white_balance(image_path, label_path):\n",
    "#    augmentation = A.Compose([\n",
    "#        A.FancyPCA(alpha=0.1, p=1.0)\n",
    "#    ])\n",
    "#    \n",
    "#    augment_image(image_path, label_path, augmentation)\n",
    "#\n",
    "## Sharpen\n",
    "#def sharpen(image_path, label_path):\n",
    "#    augmentation = A.Compose([\n",
    "#        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1.0)\n",
    "#    ])\n",
    "#    \n",
    "#    augment_image(image_path, label_path, augmentation)\n",
    "#\n",
    "## Gaussian Noise\n",
    "#def gaussian_noise(image_path, label_path, var_limit=(10.0, 50.0)):\n",
    "#    augmentation = A.Compose([\n",
    "#        A.GaussNoise(var_limit=var_limit, p=1.0)\n",
    "#    ])\n",
    "#    \n",
    "#    augment_image(image_path, label_path, augmentation)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for each specfic test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own Implementation of Object Detection System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
